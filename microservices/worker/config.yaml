server:
  port: 8081  # Changed from 8080 to avoid conflict with orchestrator
  host: 0.0.0.0
  read_timeout: 300   # 5 minutes (reduced for faster failure detection)
  write_timeout: 300
  shutdown_timeout: 60  # Increased for graceful drain at scale

database:
  host: localhost
  port: 6432  # Direct PostgreSQL for local dev (use 6432 for PgBouncer in production)
  user: crawlify
  password: dev_password
  database: crawlify
  ssl_mode: disable
  max_connections: 20   # Increased for high throughput (PgBouncer handles pooling)
  max_idle_conns: 5     # Keep more idle connections ready
  conn_max_lifetime: 60 # Shorter lifetime for better load distribution

redis:
  enabled: true
  host: localhost
  port: 6380  # Docker Compose redis port
  password: ""
  db: 0
  # Production: use Redis Cluster via Memorystore

gcp:
  project_id: "crawlify-local"
  location: "us-central1"
  pubsub_enabled: true
  pubsub_topic: "crawlify-tasks"
  pubsub_subscription: "crawlify-tasks-sub"
  pubsub_emulator_host: "localhost:8095"  # Docker Compose pubsub-emulator port
  pubsub_mode: "pull"  # Options: "pull" (local/VMs) or "push" (Cloud Run)
  storage_enabled: false  # Disable GCS for local development
  storage_bucket: "crawlify-data"
  orchestrator_url: "http://localhost:8080"  # Orchestrator service URL
  # High-throughput Pub/Sub settings (used in code)
  pubsub_max_outstanding: 50       # Messages per worker instance
  pubsub_num_goroutines: 10        # Parallel message handlers
  
  # Dead Letter Queue Settings
  pubsub_dlq_topic: "crawlify-tasks-dlq"
  pubsub_dlq_subscription: "crawlify-tasks-dlq-sub"
  pubsub_max_delivery_attempts: 5

browser:
  pool_size: 20         # Increased from 2 for parallel scraping
  headless: false        # Always headless in production
  timeout: 30000        # 30s (reduced from 60s for faster failures)
  max_concurrency: 50   # Realistic limit per worker instance
  context_lifetime: 120 # Recycle contexts every 2 min to prevent memory leaks
  driver: "playwright"  # "playwright" (default) or "http"
  log_warnings: true   # Enable warning logging (default: false)

# AI-Powered Error Recovery System
recovery:
  enabled: true
  
  # Smart triggering (prevent recovery from being too aggressive)
  window_size: 100              # Track last N results per domain
  error_rate_threshold: 0.10    # Trigger if error rate > 10%
  consecutive_threshold: 3       # Trigger after N consecutive errors
  max_recovery_attempts: 3       # Max recovery attempts per task
  
  # AI Agent Fallback (when rules don't match)
  ai_fallback_enabled: true
  llm_provider: "ollama"         # ollama, openai
  llm_model: "qwen2.5"           # qwen2.5, gpt-4o-mini
  llm_endpoint: "http://localhost:11434"
  llm_timeout: 30                # seconds
  
  # Proxy settings (used when switching proxies)
  proxy_source: "database"       # database (seeded from JSON)
  proxy_rotation: "round_robin"  # round_robin, random, least_failed

